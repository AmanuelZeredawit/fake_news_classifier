{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                              title  \\\n",
      "0           0  LAW ENFORCEMENT ON HIGH ALERT Following Threat...   \n",
      "1           1                                                NaN   \n",
      "2           2  UNBELIEVABLE! OBAMAâ€™S ATTORNEY GENERAL SAYS MO...   \n",
      "3           3  Bobby Jindal, raised Hindu, uses story of Chri...   \n",
      "4           4  SATAN 2: Russia unvelis an image of its terrif...   \n",
      "\n",
      "                                                text  label  \n",
      "0  No comment is expected from Barack Obama Membe...      1  \n",
      "1     Did they post their votes for Hillary already?      1  \n",
      "2   Now, most of the demonstrators gathered last ...      1  \n",
      "3  A dozen politically active pastors came here f...      0  \n",
      "4  The RS-28 Sarmat missile, dubbed Satan 2, will...      1  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"..data/WELFake_Dataset.csv\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 72134 entries, 0 to 72133\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  72134 non-null  int64 \n",
      " 1   title       71576 non-null  object\n",
      " 2   text        72095 non-null  object\n",
      " 3   label       72134 non-null  int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CountVectorizer for text classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '000', '0000', '000000031', '00000031', '000035', '00004', '000048', '000063', '00007']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\32467\\anaconda3\\envs\\nlp_env\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Create a series to store the labels: y\n",
    "y = df['label']\n",
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'],y,\n",
    "test_size=0.33, random_state=53)\n",
    "\n",
    "# Initialize a CountVectorizer object: count_vectorizer\n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "# Transform the training data using only the 'text' column values: count_train \n",
    "count_train = count_vectorizer.fit_transform(X_train.values)\n",
    "# Transform the test data using only the 'text' column values: count_test \n",
    "count_test = count_vectorizer.transform(X_test.values)\n",
    "# Print the first 10 features of the count_vectorizer\n",
    "print(count_vectorizer.get_feature_names()[:10])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TfidfVectorizer for text classification\n",
    "Similar to the sparse CountVectorizer created in the previous exercise, you'll work on creating tf-idf vectors for your documents. You'll set up a TfidfVectorizer and investigate some of its features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '000', '0000', '000000031', '00000031', '000035', '00004', '000048', '000063', '00007']\n",
      "  (0, 79763)\t0.0448134380402158\n",
      "  (0, 67655)\t0.0477897152422986\n",
      "  (0, 105801)\t0.06791117493695357\n",
      "  (0, 57445)\t0.09116414058408855\n",
      "  (0, 79756)\t0.035968349036515995\n",
      "  (0, 60550)\t0.03838432835123006\n",
      "  (0, 114531)\t0.07086505813835578\n",
      "  (0, 151555)\t0.056930102839383226\n",
      "  (0, 61514)\t0.07551120228367868\n",
      "  (0, 126009)\t0.04606423926784623\n",
      "  (0, 158182)\t0.043644892131251924\n",
      "  (0, 169706)\t0.04082775987417706\n",
      "  (0, 82134)\t0.040079685308456875\n",
      "  (0, 159926)\t0.0446290201996305\n",
      "  (0, 22561)\t0.051713015274712094\n",
      "  (0, 19349)\t0.03799905356638148\n",
      "  (0, 5403)\t0.05576420433807418\n",
      "  (0, 60643)\t0.06643576263992591\n",
      "  (0, 39642)\t0.05114711087344502\n",
      "  (0, 40953)\t0.040224337764138786\n",
      "  (0, 41927)\t0.08655782644474604\n",
      "  (0, 20577)\t0.0665522893065148\n",
      "  (0, 128656)\t0.07157295982801841\n",
      "  (0, 175755)\t0.03043408330642221\n",
      "  (0, 55895)\t0.06601753930461074\n",
      "  :\t:\n",
      "  (4, 55029)\t0.04621917150706667\n",
      "  (4, 81779)\t0.05299888084584878\n",
      "  (4, 154367)\t0.123682648451027\n",
      "  (4, 96712)\t0.16566003697897863\n",
      "  (4, 97292)\t0.036737869942673196\n",
      "  (4, 147411)\t0.11998508023953926\n",
      "  (4, 42819)\t0.2760090791039596\n",
      "  (4, 48148)\t0.1889865373030365\n",
      "  (4, 129516)\t0.10488143077156378\n",
      "  (4, 80213)\t0.034520028067080766\n",
      "  (4, 67650)\t0.03652586590003237\n",
      "  (4, 149849)\t0.037648629897193045\n",
      "  (4, 136626)\t0.05200995509076843\n",
      "  (4, 116831)\t0.030226364767122073\n",
      "  (4, 76794)\t0.03264907813818619\n",
      "  (4, 72930)\t0.0397343344102488\n",
      "  (4, 54113)\t0.03973109135782736\n",
      "  (4, 58156)\t0.039311299429303025\n",
      "  (4, 77982)\t0.07393834342579675\n",
      "  (4, 44577)\t0.03447998509195328\n",
      "  (4, 112779)\t0.024400753993762764\n",
      "  (4, 70353)\t0.03326197926056796\n",
      "  (4, 122831)\t0.01897322048380234\n",
      "  (4, 141431)\t0.014810675294997373\n",
      "  (4, 73926)\t0.034323244519788174\n"
     ]
    }
   ],
   "source": [
    "# Import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Initialize a TfidfVectorizer object: tfidf_vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english',max_df=0.7)\n",
    "# Transform the training data: tfidf_train \n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train.values)\n",
    "# Transform the test data: tfidf_test \n",
    "tfidf_test = tfidf_vectorizer.transform(X_test.values)\n",
    "# Print the first 10 features\n",
    "print(tfidf_vectorizer.get_feature_names()[:10])\n",
    "# Print the first 5 vectors of the tfidf training data\n",
    "print(tfidf_train[:5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspecting the vectors\n",
    "To get a better idea of how the vectors work, you'll investigate them by converting them into pandas DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the CountVectorizer DataFrame: count_df\n",
    "count_df = pd.DataFrame(count_train.A, columns=count_vectorizer.get_feature_names())\n",
    "# Create the TfidfVectorizer DataFrame: tfidf_df\n",
    "tfidf_df =  pd.DataFrame(tfidf_train.A, columns=tfidf_vectorizer.get_feature_names())\n",
    "# Print the head of count_df\n",
    "print(count_df.head())\n",
    "# Print the head of tfidf_df\n",
    "print(tfidf_df.head())\n",
    "# calculate the difference in columns: difference\n",
    "difference = set(count_df.columns) - set(tfidf_df.columns)\n",
    "print(difference)\n",
    "# Check whether the DataFrames are equal\n",
    "print(count_df.equals(tfidf_df))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### raining and testing the \"fake news\" model with CountVectorizer\n",
    "Now it's your turn to train the \"fake news\" model using the features you identified and extracted. In this first exercise you'll train and test a Naive Bayes model using the CountVectorizer data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8900796340223653\n",
      "[[10493  1050]\n",
      " [ 1545 10520]]\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary module\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Instantiate a Multinomial Naive Bayes classifier: nb_classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "# Fit the classifier to the training data\n",
    "nb_classifier.fit(count_train, y_train)\n",
    "# Create the predicted tags: pred\n",
    "pred = nb_classifier.predict(count_test)\n",
    "# Calculate the accuracy score: score\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(score)\n",
    "# Calculate the confusion matrix: cm\n",
    "cm = metrics.confusion_matrix(y_test, pred, labels=[0,1])\n",
    "print(cm)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and testing the \"fake news\" model with TfidfVectorizer\n",
    "Now that you have evaluated the model using the CountVectorizer, you'll do the same using the TfidfVectorizer with a Naive Bayes model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.866867163673331\n",
      "[[10100  1443]\n",
      " [ 1700 10365]]\n"
     ]
    }
   ],
   "source": [
    "# Create a Multinomial Naive Bayes classifier: nb_classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "# Fit the classifier to the training data\n",
    "nb_classifier.fit(tfidf_train, y_train)\n",
    "# Create the predicted tags: pred\n",
    "pred =  nb_classifier.predict(tfidf_test)\n",
    "# Calculate the accuracy score: score\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(score)\n",
    "# Calculate the confusion matrix: cm\n",
    "cm = metrics.confusion_matrix(y_test, pred, labels=[0,1])\n",
    "print(cm)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Improving your model\n",
    "Your job in this exercise is to test a few different alpha levels using the Tfidf vectors to determine if there is a better performing combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha:  0.0\n",
      "Score:  0.891562182311081\n",
      "\n",
      "Alpha:  0.1\n",
      "Score:  0.8805913249745849\n",
      "\n",
      "Alpha:  0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\32467\\anaconda3\\envs\\nlp_env\\lib\\site-packages\\sklearn\\naive_bayes.py:557: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  % _ALPHA_MIN\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.8770755676042019\n",
      "\n",
      "Alpha:  0.30000000000000004\n",
      "Score:  0.874364622161979\n",
      "\n",
      "Alpha:  0.4\n",
      "Score:  0.8722466960352423\n",
      "\n",
      "Alpha:  0.5\n",
      "Score:  0.8711453744493393\n",
      "\n",
      "Alpha:  0.6000000000000001\n",
      "Score:  0.8703405625211793\n",
      "\n",
      "Alpha:  0.7000000000000001\n",
      "Score:  0.8691968824127414\n",
      "\n",
      "Alpha:  0.8\n",
      "Score:  0.8686462216197899\n",
      "\n",
      "Alpha:  0.9\n",
      "Score:  0.8675872585564216\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the list of alphas: alphas\n",
    "alphas = np.arange(0,1,0.1)\n",
    "\n",
    "# Define train_and_predict()\n",
    "def train_and_predict(alpha):\n",
    "    # Instantiate the classifier: nb_classifier\n",
    "    nb_classifier = MultinomialNB(alpha=alpha)\n",
    "    # Fit to the training data\n",
    "    nb_classifier.fit(tfidf_train, y_train)\n",
    "    # Predict the labels: pred\n",
    "    pred = nb_classifier.predict(tfidf_test)\n",
    "    # Compute accuracy: score\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    return score\n",
    "\n",
    "# Iterate over the alphas and print the corresponding score\n",
    "for alpha in alphas:\n",
    "    print('Alpha: ', alpha)\n",
    "    print('Score: ', train_and_predict(alpha))\n",
    "    print()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspecting your model\n",
    "Now that you have built a \"fake news\" classifier, you'll investigate what it has learned. You can map the important vector weights back to actual words using some simple inspection techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [(-12.973138524212128, '000000031'), (-12.973138524212128, '00000031'), (-12.973138524212128, '00004'), (-12.973138524212128, '000063'), (-12.973138524212128, '00042'), (-12.973138524212128, '0009'), (-12.973138524212128, '000cases'), (-12.973138524212128, '000ft'), (-12.973138524212128, '000m'), (-12.973138524212128, '000x'), (-12.973138524212128, '00106'), (-12.973138524212128, '00155'), (-12.973138524212128, '0019'), (-12.973138524212128, '00193'), (-12.973138524212128, '001st'), (-12.973138524212128, '0020'), (-12.973138524212128, '0024'), (-12.973138524212128, '00458'), (-12.973138524212128, '0050'), (-12.973138524212128, '005380')]\n",
      "1 [(-7.414572460259855, 'state'), (-7.3929470644789514, 'white'), (-7.385637235987291, 'media'), (-7.384880760087839, 'time'), (-7.376661963703968, 'campaign'), (-7.374418879355726, '2016'), (-7.371352750938148, 'america'), (-7.3435049592447434, 'new'), (-7.322418475677631, 'news'), (-7.279459070867028, 'election'), (-7.1575736818489535, 'donald'), (-7.136286404438364, 'like'), (-7.035640028948726, 'just'), (-7.00090341626842, 'said'), (-6.953166631775209, 'president'), (-6.9442684721475345, 'obama'), (-6.871162293194987, 'people'), (-6.718642967468635, 'hillary'), (-6.483551643829406, 'clinton'), (-5.833839759981218, 'trump')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\32467\\anaconda3\\envs\\nlp_env\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "c:\\Users\\32467\\anaconda3\\envs\\nlp_env\\lib\\site-packages\\sklearn\\utils\\deprecation.py:103: FutureWarning: Attribute `coef_` was deprecated in version 0.24 and will be removed in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Get the class labels: class_labels\n",
    "class_labels = nb_classifier.classes_\n",
    "# Extract the features: feature_names\n",
    "feature_names = tfidf_vectorizer.get_feature_names()\n",
    "# Zip the feature names together with the coefficient array and sort by weights: feat_with_weights\n",
    "feat_with_weights = sorted(zip(nb_classifier.coef_[0], feature_names))\n",
    "# Print the first class label and the top 20 feat_with_weights entries\n",
    "print(class_labels[0], feat_with_weights[:20])\n",
    "# Print the second class label and the bottom 20 feat_with_weights entries\n",
    "print(class_labels[1], feat_with_weights[-20:])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
